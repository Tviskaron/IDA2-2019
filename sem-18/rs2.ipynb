{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка рекомендательной системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Примечание: в контексте данной работы единицами рекомендаций будут являвляться фильмы, т.к. использование этого термина будет удобно с точки зрения используемого датасета._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно выделить два основных типа рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content-based**\n",
    "\n",
    "* Пользователю рекомендуются фильмы, похожие на те, которые он уже посмотрел.\n",
    "* Похожести оцениваются по признакам содержимого объектов.\n",
    "* Сильная зависимость от предметной области, полезность рекомендаций ограничена.\n",
    "\n",
    "Коллаборативная фильтрация (**Collaborative Filtering**)\n",
    "\n",
    "* Для рекомендации используется история оценок как самого пользователя, так и других пользователей.\n",
    "* Более универсальный подход, часто дает лучший результат.\n",
    "* Есть свои проблемы (например, холодный старт)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев алгоритмы коллаборативной фильтрации (CF) показывают лучший результат, чем content-based системы. В данной работе будут рассматриваться два типа CF: **Memory-Based Collaborative Filtering** и **Model-Based Collaborative filtering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе используется MovieLens Dataset (Small). Посмотреть информацию или скачать датасет можно [отсюда](https://grouplens.org/datasets/movielens/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем датасет\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# смотрим на табличку\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим количество пользователей и фильмов\n",
    "# Ваш код здесь\n",
    "n_users = \n",
    "n_items = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Users: {}, Items: {}'.format(n_users, n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы можно было удобно работать дальше, необходимо отмасштабировать \n",
    "# значения в колонке movieId (новые значения будут в диапазоне от 1 до\n",
    "# количества фильмов)\n",
    "input_list = df['movieId'].unique()\n",
    "\n",
    "def scale_movie_id(input_id):\n",
    "    return np.where(input_list == input_id)[0][0] + 1\n",
    "\n",
    "df['movieId'] = df['movieId'].apply(scale_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "\n",
    "# делим данные на тренировочный и тестовый наборы (test_size=0.2)\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory-Based Collaborative Filtering подходы можно разделить на две части: **user-item filtering** and **item-item filtering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В user-item filtering мы:\n",
    "\n",
    "1. Берём исходного пользователя\n",
    "2. Находим группу пользователей, которая максимально похожа на него (основываясь, например, оценках) и узнаём, какие фильмы понравились этой группе.\n",
    "3. Нашему исходному пользователю рекомендуем фильмы, которые нравятся найденной группе пользователей.\n",
    "\n",
    "На входе пользователь, на выходе – рекомендация фильмов для данного пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В item-item filtering мы:\n",
    "    \n",
    "1. Берём какой-либо фильм\n",
    "2. Находим пользователей, которым нравится этот фильм\n",
    "3. Смотрим на фильмы, которые нравятся найденным пользователям и выводим их в качестве рекомендации к исходному товару\n",
    "\n",
    "На входе фильм, на выходе – рекомендация в виде похожих фильмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Item-Item Collaborative Filtering: \"Пользователям, которым нравится данный фильм, может так же понравиться это ...\"\n",
    "* User-Item Collaborative Filtering: \"Похожим на вас пользователям нравится это ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обоих случаях нам необходимо создать user-item матрицу, которая будет выглядеть следующим образом:\n",
    "\n",
    "|       | Item1 | Item2 | Item3 |\n",
    "|-------|-------|-------|-------|\n",
    "| User1 |   5   |   3   |   4   |\n",
    "| User2 |   4   |   0   |   0   |\n",
    "| User3 |   0   |   0   |   0   |\n",
    "\n",
    "В ячейках матрицы будет записана информация об оценке фильма $m$ пользователя $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём две user-item матрицы – для обучения и для теста\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1] - 1, line[2] - 1] = line[3]  \n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1] - 1, line[2] - 1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы построим данную матрицу, на её основе необходимо будет рассчитать две новые матрицы с коэффициентами сходства (похожести, близости) для пользователей и для фильмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики близости в данной работе используется косинусное расстояние между векторами пользователей (фильмов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для пользователей:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s_{u}^{cos}(u_k, u_a) = \\frac{u_k \\cdot  u_a}{\\left \\| u_k \\right \\| \\left \\| u_a \\right \\|} = \\frac{\\sum x_{k,m} x_{a,m}}{\\sqrt{\\sum x_{k,m}^2 \\sum x_{a,m}^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для фильмов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ s_{u}^{cos}(i_m, i_b) = \\frac{i_m \\cdot  i_b}{\\left \\| i_m \\right \\| \\left \\| i_b \\right \\|} = \\frac{\\sum x_{a,m} x_{a,b}}{\\sqrt{\\sum x_{a,m}^2 \\sum x_{a,b}^2}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# считаем косинусное расстояние для пользователей и фильмов\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица \"похожести\" для пользователей имеет следующий вид (аналогичную структуру имеет и матрицы для фильмов):\n",
    "\n",
    "|       | User1 | User1 | User3 |\n",
    "|-------|-------|-------|-------|\n",
    "| User1 |   0   | 0.87  | 0.99  |\n",
    "| User2 |   123   |   0   |   123123   |\n",
    "| User3 |   123   |   123   |   0  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предсказания в user-based CF необходимо применить следующую формулу:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{x}_{k,m} = \\overline{x}_k + \\frac{\\sum_{u_a} sim_u(u_k, u_a)(x_{a,m} - \\overline{x}_{u_a})}{\\sum_{u_a} \\left | sim_u(u_k, u_a) \\right |} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для item-based CF:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{x}_{k,m} = \\frac{\\sum_{i_b} sim_i(i_m, i_b)(x_{k,b})}{\\sum_{i_b} \\left | sim_i(i_m, i_b) \\right |} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])     \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества предсказания используем метрику RMSE (Root Mean Square Error, cреднеквадратичная ошибка):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSE = \\sqrt{\\frac{1}{N}\\sum (x_i - \\hat{x}_i)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    # Ваш код здесь\n",
    "    result = \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based Collaborative Filtering основана на разложении матрицы. В данной работе используется метод разложения, который называется **singular value decomposition** (SVD, cингулярное разложение). Смысл этого разложения в том, что исходную матрицу $X$ мы разбиваем на произведение ортогональных матриц $U$ и $V^T$ и диагональной матрицы $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X = UV^TS $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае $X$ – разреженная (состоящая преимущественно из нулей) user-item матрица. Разложив её на компоненты, мы можем их вновь перемножить и получить \"восстановленную\" матрицу $\\hat{X}$. Матрица $\\hat{X}$ и будет являться нашим предсказанием – метод SVD сделал сам за нас всё работу и заполнил пропуски в исходной матрице $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ UV^TS \\approx \\hat{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем SVD\n",
    "u, s, vt = svds(train_data_matrix, k=10)\n",
    "\n",
    "# предствляем s в виде диагонольной матрицы\n",
    "# Ваш код здесь\n",
    "s_diag_matrix =\n",
    "\n",
    "# считаем предсказание\n",
    "# Ваш код здесь \n",
    "X_pred = \n",
    "\n",
    "# выводим метрику\n",
    "print('User-based CF RMSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пару слов стоит сказать о наиболее эффективной на практике гибридной рекомендательной системе. Его суть заключается в том, чтобы комбинировать в себе сontent-based модели и сollaborative filtering. Используя дополнительную информацию о фильмах (жанр, теги, год выпуска и т.д.) и мощь алгоритмов коллаборативной фильтрации, можно добиться впечатляющего результата."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
