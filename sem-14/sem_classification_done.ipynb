{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoqdCBI_YeVz"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5fsFjoTYeV4"
   },
   "source": [
    "Посмотрим на данные: это отзывы о ресторанах и оценка. Будем решать многоклассовую классификацию. Датасет можно сказать по ссылке: https://www.dropbox.com/s/q5sko5ic9rdio14/classification_train.data?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "id": "xcOjXM6LY3U8",
    "outputId": "fd2f9ec8-88fe-48de-b8f4-2e08d915375a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-05 15:48:42--  https://www.dropbox.com/s/q5sko5ic9rdio14/classification_train.data\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/q5sko5ic9rdio14/classification_train.data [following]\n",
      "--2019-06-05 15:48:42--  https://www.dropbox.com/s/raw/q5sko5ic9rdio14/classification_train.data\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com/cd/0/inline/AiO7pYUu3D8Y9RfwFV3fuY-UD_3ZWjeQLCBi0CXM6hEjHmyn8PVsPUNyQtjCO5TzIWlkqr8E766SPzFstoy25XYp_YWX4UhyY7GpKySEVFVpqg/file# [following]\n",
      "--2019-06-05 15:48:43--  https://ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com/cd/0/inline/AiO7pYUu3D8Y9RfwFV3fuY-UD_3ZWjeQLCBi0CXM6hEjHmyn8PVsPUNyQtjCO5TzIWlkqr8E766SPzFstoy25XYp_YWX4UhyY7GpKySEVFVpqg/file\n",
      "Resolving ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com (ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com (ucafaf884baf87829c3e0070fbe2.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 106448851 (102M) [text/plain]\n",
      "Saving to: ‘classification_train.data’\n",
      "\n",
      "classification_trai 100%[===================>] 101.52M  1.29MB/s    in 74s     \n",
      "\n",
      "Last-modified header missing -- time-stamps turned off.\n",
      "2019-06-05 15:49:58 (1.37 MB/s) - ‘classification_train.data’ saved [106448851/106448851]\n",
      "\n",
      "classification_train.data      sem_classification.ipynb\n",
      "sem_classification_done.ipynb\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/q5sko5ic9rdio14/classification_train.data -N\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "pKGlXvIuYeV5",
    "outputId": "1059f006-babc-4434-b061-669a3be01091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\tSentiment\tText\r\n",
      "0\t1\tIncredibly disappointing service. I mean really, really bad.\\n\\nWe placed an order for delivery at 6:30 pm on a Tuesday night, not the busiest night of the week, I'm sure. We were given an estimate of 30-40 minutes. After an hour my husband called to make sure our order wasn't forgotten. The young girl on the phone said that they were very busy and the driver was on his way to our house (less than a mile from the restaurant) at that time and should arrive in 10 minutes. After another 30 minutes we called back and asked to please cancel the order, after 1 1/2 hours we no longer wanted the food. The girl on the phone shouted at my husband that none of this was her fault and was reluctant to cancel our order. She wanted to charge us for food we never received!\\n\\nThe food is just not good enough for such poor service. If 18 year old college students can't answers phones and take simple orders don't hire them. It's simple.\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 2 classification_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "57JuKfwgYeV9",
    "outputId": "13d70599-0d34-4014-a758-23ea82cadcb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102583 classification_train.data\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l classification_train.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w5VY1hFBYeWE"
   },
   "source": [
    "Считаем выборку, поделим на трейн и тест так, чтобы в x_train был raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "rIdB1RJAhadi",
    "outputId": "eafec2f8-e844-4773-ed64-2829a4b94d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip: not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "_i7n7sKfYeWF",
    "outputId": "255cba4d-701d-46f0-a42a-79e89e671f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 \n",
      "data: Incredibly disappointing service. I mean really, really bad.\\n\\nWe placed an order for delivery at 6:30 pm on a Tuesday night, not the busiest night of the week, I'm sure. We were given an estimate of 30-40 minutes. After an hour my husband called to make sure our order wasn't forgotten. The young girl on the phone said that they were very busy and the driver was on his way to our house (less than a mile from the restaurant) at that time and should arrive in 10 minutes. After another 30 minutes we called back and asked to please cancel the order, after 1 1/2 hours we no longer wanted the food. The girl on the phone shouted at my husband that none of this was her fault and was reluctant to cancel our order. She wanted to charge us for food we never received!\\n\\nThe food is just not good enough for such poor service. If 18 year old college students can't answers phones and take simple orders don't hire them. It's simple.\n"
     ]
    }
   ],
   "source": [
    "train_file = csv.reader(open('classification_train.data'), delimiter='\\t')\n",
    "train_set = list(train_file)\n",
    "_, train_label, train_data = zip(*train_set[1:])\n",
    "print(\"label:\", train_label[0], \"\\ndata:\", train_data[0], )\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(train_data, train_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "XL-YpIEAYeWJ",
    "outputId": "2a8fde15-04b9-424d-960b-9c60d2b8f2be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like this location because they have a drive-thru. Even though there is almost always a long line, they get you on your way fast. The staff is friendly and competent. Also, they rarely run out of anything (other locations seem to go through their entire inventory of breakfast sandwiches and scones by 9am).\\\\n\\\\nIf you are the type that does not drink your morning coffee inside a moving vehicle, they also have comfy chairs inside and decent patio seating.  The patio faces the parking lot and drive-thru but it does have shade umbrellas so it can be very pleasant in the morning.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_Xu52b4EYeWN",
    "outputId": "2567ca78-62d2-49e7-f345-47f37a6b7964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PGcCEC7YeWQ"
   },
   "source": [
    "\"Тупое\" решение:\n",
    "\n",
    "Посмотрим что будет, если применить самое простое решение: найти 100 самых частотных слов и использовать их в качестве признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irKKiHI6YeWR"
   },
   "source": [
    "- Найдем топ 100 самых частотных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQQ7G8tPYeWS"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7MRn-wA4YeWV",
    "outputId": "13228f20-b03a-4d02-9964-dc5cb792fbfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique \"words\":  484082\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_bag_with_freq(data):\n",
    "    result = Counter()\n",
    "    for s in data:\n",
    "        result.update(s.strip().split())\n",
    "    return list(result.items())\n",
    "  \n",
    "train_bag = create_bag_with_freq(x_train)\n",
    "print('Number of unique \"words\": ', len(train_bag))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "d6shOEYTjpqg",
    "outputId": "020a1c32-b7f3-451f-a41b-2fa94c4b01e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 654951),\n",
       " ('and', 492240),\n",
       " ('a', 411657),\n",
       " ('I', 385802),\n",
       " ('to', 359227),\n",
       " ('of', 248340),\n",
       " ('was', 240102),\n",
       " ('is', 184703),\n",
       " ('for', 167194),\n",
       " ('in', 162966)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_word = sorted(train_bag, key=lambda x: x[1], reverse=True)[:100]\n",
    "most_frequent_word[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtMqY84IYeWY"
   },
   "source": [
    "В наивный байесовский классификатор надо подать текст в определенном формате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATT9f8MsYeWY"
   },
   "outputs": [],
   "source": [
    "def make_bow_sample(bow, sample):\n",
    "    for s in sample:\n",
    "        s = s.strip().split()\n",
    "        yield { word:word in s for word, _ in bow}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n76t5UzNYeWb"
   },
   "outputs": [],
   "source": [
    "bow_train = [(x, y) for x, y in zip(make_bow_sample(most_frequent_word, x_train), y_train)]\n",
    "bow_validate = [x for x in make_bow_sample(most_frequent_word, x_validate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1835
    },
    "colab_type": "code",
    "id": "xe14GWfpYeWd",
    "outputId": "7fb6f38a-fe30-4bc3-f7d3-23f88d75a62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'the': True,\n",
       "  'and': True,\n",
       "  'a': True,\n",
       "  'I': True,\n",
       "  'to': True,\n",
       "  'of': True,\n",
       "  'was': False,\n",
       "  'is': True,\n",
       "  'for': False,\n",
       "  'in': True,\n",
       "  'it': True,\n",
       "  'that': True,\n",
       "  'with': False,\n",
       "  'but': True,\n",
       "  'my': False,\n",
       "  'on': True,\n",
       "  'you': True,\n",
       "  'The': True,\n",
       "  'have': True,\n",
       "  'this': True,\n",
       "  'had': False,\n",
       "  'they': True,\n",
       "  'not': True,\n",
       "  'are': True,\n",
       "  'at': False,\n",
       "  'were': False,\n",
       "  'we': False,\n",
       "  'so': True,\n",
       "  'be': True,\n",
       "  'as': False,\n",
       "  'like': True,\n",
       "  'place': False,\n",
       "  'just': False,\n",
       "  'out': True,\n",
       "  'or': False,\n",
       "  'me': False,\n",
       "  'get': True,\n",
       "  'food': False,\n",
       "  'very': True,\n",
       "  'good': False,\n",
       "  'all': False,\n",
       "  'from': False,\n",
       "  'there': True,\n",
       "  'their': True,\n",
       "  'one': False,\n",
       "  'if': False,\n",
       "  'about': False,\n",
       "  'some': False,\n",
       "  'would': False,\n",
       "  'up': False,\n",
       "  'an': False,\n",
       "  'really': False,\n",
       "  'our': False,\n",
       "  'when': False,\n",
       "  'been': False,\n",
       "  'which': False,\n",
       "  'go': True,\n",
       "  'your': True,\n",
       "  'can': True,\n",
       "  'great': False,\n",
       "  'here': False,\n",
       "  '-': False,\n",
       "  'It': False,\n",
       "  'We': False,\n",
       "  'time': False,\n",
       "  'what': False,\n",
       "  'will': False,\n",
       "  'more': False,\n",
       "  'by': True,\n",
       "  'only': False,\n",
       "  \"it's\": False,\n",
       "  'back': False,\n",
       "  'because': True,\n",
       "  \"don't\": False,\n",
       "  'They': False,\n",
       "  'little': False,\n",
       "  'other': False,\n",
       "  'also': True,\n",
       "  'has': False,\n",
       "  \"I'm\": False,\n",
       "  'than': False,\n",
       "  'got': False,\n",
       "  'even': False,\n",
       "  \"I've\": False,\n",
       "  'no': False,\n",
       "  'This': False,\n",
       "  'do': False,\n",
       "  'ordered': False,\n",
       "  'service': False,\n",
       "  'could': False,\n",
       "  'My': False,\n",
       "  'always': True,\n",
       "  'pretty': False,\n",
       "  \"didn't\": False,\n",
       "  'them': False,\n",
       "  'us': False,\n",
       "  'much': False,\n",
       "  'he': False,\n",
       "  'love': False,\n",
       "  'nice': False},\n",
       " '3')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVhwyXfnYeWh"
   },
   "source": [
    "Воспользуемся наивным байесовским классификатором. \n",
    "Плюс данного классификатора - можно посмотреть какиме слова оказались наиболее полезными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "Ee-dkAmTYeWh",
    "outputId": "e042753d-d9d7-4ec8-c352-647f10b1a844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    love = True                5 : 1      =      3.5 : 1.0\n",
      "                   great = True                5 : 1      =      3.1 : 1.0\n",
      "                     was = False               5 : 1      =      2.7 : 1.0\n",
      "                  always = True                5 : 1      =      2.6 : 1.0\n",
      "                  pretty = True                3 : 1      =      2.5 : 1.0\n",
      "                      no = True                1 : 5      =      2.4 : 1.0\n",
      "                      he = True                1 : 4      =      2.4 : 1.0\n",
      "                      to = False               4 : 1      =      2.3 : 1.0\n",
      "                  didn't = True                2 : 5      =      2.3 : 1.0\n",
      "                    nice = True                4 : 1      =      2.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb = nltk.NaiveBayesClassifier.train(bow_train)\n",
    "print(nb.show_most_informative_features())\n",
    "predicted = [nb.classify(o) for o in bow_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pu8RP_w_YeWk"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EJCvFBMYeWl"
   },
   "source": [
    "Замерьте качество с помощью accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c3LagnDYYeWm",
    "outputId": "b606ce1e-4e85-4911-8f78-1f383ff55aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3787605441513482\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', np.mean(np.array(list(map(float,predicted))) == np.array(list(map(float, y_validate)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhV1d7B_YeWn"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQ8idO_2YeWp"
   },
   "outputs": [],
   "source": [
    "y_train = list(map(float, y_train))\n",
    "y_validate = list(map(float, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRplxwYGYeWs"
   },
   "source": [
    "Обучите TfidfVectorizer на трейне, примените на тесте.\n",
    "\n",
    "Почему надо действовать именно так, почему нельзя обучить и на трейне, и на тесте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGlJQECjYeWs"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(encoding=u'utf-8', ngram_range=(1, 2), analyzer='word')\n",
    "Xtrain = tfidf.fit_transform(x_train)\n",
    "Xtest = tfidf.transform(x_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "mInnW6FEYeWv"
   },
   "source": [
    "- Попробуйте LodisticRegression, LinearSVC, SGDClassifier с какой-нибудь функцией потерь.\n",
    "- При обучении  SGDClassifier не забудьте поставить побольше итераций, так как это итеративный метод\n",
    "- параметр class_weight='balanced' может быть полезен. Что он означает?\n",
    "- Можете повариьировать так же параметры TF-IDF vectorizer\n",
    "- Попробовать прологарифмировать частоты np.log1p(), или другое нелинейное преобразование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Re7RLdV9YeWw"
   },
   "source": [
    "SVM vs LinearSVC\n",
    "(LinearSVC быстрее, но не выадет вероятностей, а лишь расстояние до решающей границы. Перевести в вероятности можно, откалибровав http://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "eHGloAONYeWw",
    "outputId": "5c693b77-c5c4-4275-c8a8-ee9566750b8b"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1, n_jobs=-1)\n",
    "lr.fit(Xtrain, y_train)\n",
    "lr_pr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmYSjiNxYeWz"
   },
   "source": [
    "Замерьте качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AO9Sl6b2YeWz",
    "outputId": "f6418053-c7c2-48f0-a673-83a8f4e762ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5904237164171827\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', np.mean(np.array(list(map(float,lr_pr)))== np.array(list(map(float, y_validate)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CT-uTjF-YeW1"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YFhx7GBYeW3"
   },
   "outputs": [],
   "source": [
    "# clf = [LogisticRegression(n_jobs=-1)\n",
    "# LinearSVC(C=1, loss='hinge', class_weight='balanced'),\n",
    "# SGDClassifier(loss='modified_huber', class_weight='balanced', alpha=1e-2, n_iter=50, n_jobs=-1),\n",
    "# SGDClassifier(loss='squared_hinge', class_weight='balanced', alpha=1e-2, n_iter=50, n_jobs=-1),\n",
    "# SGDClassifier(loss='hinge',class_weight='balanced', alpha=1e-2, random_state=3, n_iter=50, n_jobs=-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_ppt48gYeW5"
   },
   "source": [
    "Какой алгоритм сработал лучше свего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evy_O5Y7YeW6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oyxy-WbYeW8"
   },
   "source": [
    "Когда обучаем многоклассовую классификацию для такой задачи, не учитываем то, что метки 1 и 2 более похожи между собой, чем 4 и 5. Как это можно было бы учесть при обучении модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijcC_Y2IYeW8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMTeft6iYeW-"
   },
   "source": [
    "Переходим к нейросетевым подходам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kKhXFBCzYeW-",
    "outputId": "ef425fec-acf1-432a-e54c-51d5aeb3d0ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Sr6094cXYeW_",
    "outputId": "7cd36488-0d1a-462c-efc4-486400cf0700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like this location because they have a drive-thru. Even though there is almost always a long line, they get you on your way fast. The staff is friendly and competent. Also, they rarely run out of anything (other locations seem to go through their entire inventory of breakfast sandwiches and scones by 9am).\\\\n\\\\nIf you are the type that does not drink your morning coffee inside a moving vehicle, they also have comfy chairs inside and decent patio seating.  The patio faces the parking lot and drive-thru but it does have shade umbrellas so it can be very pleasant in the morning.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvGjlD_qtqGA"
   },
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 100\n",
    "VOCABULARY_SIZE = 50000\n",
    "EMBEDDING_DIM = 30\n",
    "DIMS = 56\n",
    "MAX_FEATURES = 5000\n",
    "batch_size = 32\n",
    "\n",
    "nb_filter = 50\n",
    "filter_length = 3\n",
    "hidden_dims = 50\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gLbMbUADYeXB",
    "outputId": "3c4117b1-58b7-4310-959f-073cc315a92c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7f9b729670f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE07jt0rYeXC"
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "X_train = tokenizer.sequences_to_matrix(sequences, mode='count')\n",
    "sequences = tokenizer.texts_to_sequences(x_validate)\n",
    "X_test = tokenizer.sequences_to_matrix(sequences, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4lX9hKifYeXD",
    "outputId": "68efebf1-b94c-488e-f45e-e41f1dcd7ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82035, 5000), (20509, 5000))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQyPpWfwYeXE"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)[:, 1:]\n",
    "y_test = np_utils.to_categorical(y_validate)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "id": "Wle1Rt3wYeXG",
    "outputId": "79a505f8-17fe-4daa-9bb8-4dd33ecea4bc"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(MAX_FEATURES,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "vwugyP8JYeXI",
    "outputId": "4ed3e2db-bdb8-4aa9-8d80-e8919358db13"
   },
   "outputs": [],
   "source": [
    "pr = model.predict(X_test)\n",
    "pr_nn = list(np.argmax(pr, axis=1))\n",
    "print(list(pr_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlqrNJPGYeXK"
   },
   "source": [
    "Замерьте качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WV3t70ncYeXL",
    "outputId": "6478321e-168e-46e3-93a2-761c77b85e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5309376371349164"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = model.predict(X_test)\n",
    "np.mean(np.argmax(pr, axis=1) == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hcZSKVFYeXN"
   },
   "source": [
    "Теперь пробуем LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRvliQ2IYeXN"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "sequences = tokenizer.texts_to_sequences(x_train)\n",
    "X_train = sequence.pad_sequences(sequences, maxlen=TEXT_LENGTH)\n",
    "sequences = tokenizer.texts_to_sequences(x_validate)\n",
    "X_test = sequence.pad_sequences(sequences, maxlen=TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anhKGjZDYeXP"
   },
   "outputs": [],
   "source": [
    "max_review_length = max([len(el) for el in X_train])\n",
    "top_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "colab_type": "code",
    "id": "3CxbJyvLYeXR",
    "outputId": "5adb4270-16a1-451e-a5de-d2c8fb98a215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 213,705\n",
      "Trainable params: 213,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 82035 samples, validate on 20509 samples\n",
      "Epoch 1/3\n",
      "82035/82035 [==============================] - 155s 2ms/step - loss: 0.4120 - acc: 0.8101 - val_loss: 0.3594 - val_acc: 0.8255\n",
      "Epoch 2/3\n",
      "82035/82035 [==============================] - 143s 2ms/step - loss: 0.3500 - acc: 0.8318 - val_loss: 0.3553 - val_acc: 0.8270\n",
      "Epoch 3/3\n",
      "82035/82035 [==============================] - 149s 2ms/step - loss: 0.3360 - acc: 0.8388 - val_loss: 0.3468 - val_acc: 0.8319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b5623cb00>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZT8osq7_YeXV"
   },
   "source": [
    "Замерьте качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eywTXMH7YeXW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529767419181822"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = model.predict(X_test)\n",
    "np.mean(np.argmax(pr, axis=1) == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNDLfWCz1ro0"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "6lAklqwWYeXX"
   },
   "source": [
    "Теперь пробуем добавить сверточный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "id": "cXJyjlRoYeXY",
    "outputId": "7592bd8a-5192-4df7-8607-8997d90237d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 216,809\n",
      "Trainable params: 216,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 82035 samples, validate on 20509 samples\n",
      "Epoch 1/3\n",
      "82035/82035 [==============================] - 88s 1ms/step - loss: 0.4003 - acc: 0.8125 - val_loss: 0.3572 - val_acc: 0.8267\n",
      "Epoch 2/3\n",
      "82035/82035 [==============================] - 83s 1ms/step - loss: 0.3417 - acc: 0.8350 - val_loss: 0.3437 - val_acc: 0.8339\n",
      "Epoch 3/3\n",
      "82035/82035 [==============================] - 85s 1ms/step - loss: 0.3268 - acc: 0.8431 - val_loss: 0.3400 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b5fbe9518>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZuGOfiEYeXc"
   },
   "source": [
    "Замерьте качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "phFy2rWCYeXc",
    "outputId": "d6d71a29-1e14-4f9d-8610-1d873bfa6123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5611195085084597"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = model.predict(X_test)\n",
    "np.mean(np.argmax(pr, axis=1) == np.argmax(y_test, axis=1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sem_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
